# BiaPy version: 3.5.13

SYSTEM:
    NUM_CPUS: -1

PROBLEM:
    TYPE: SEMANTIC_SEG
    NDIM: 3D

DATA:
    PATCH_SIZE: (32, 128, 128, 3)
    TRAIN:
        PATH: /home/yasminebenjelloun/dataset/segmentation_data_moyen_1000/train/raw
        GT_PATH: /home/yasminebenjelloun/dataset/segmentation_data_moyen_1000/train/label
        IN_MEMORY: True
        #PADDING: (4, 16, 16)
    VAL:
        #SPLIT_TRAIN: 0.2
        CROSS_VAL: True               
        #FROM_TRAIN: False  
        
    TEST:
        PATH: /home/yasminebenjelloun/dataset/segmentation_data_moyen_1000/test/raw
        GT_PATH: /home/yasminebenjelloun/dataset/segmentation_data_moyen_1000/test/label
        IN_MEMORY: True
        LOAD_GT: True
        #PADDING: (4,8,8)
        PADDING: (4, 16, 16)
    NORMALIZATION:
        TYPE: 'scale_range'
        #TYPE: "zero_mean_unit_variance"


AUGMENTOR:
    # DROPOUT: True
    # GRIDMASK: True
    # CUTOUT: True
    ENABLE: True
    DA_PROB: 0.5
    CUTOUT: False
    # GRIDMASK: True
    CUTBLUR: True
    RANDOM_ROT: True # quels axes à vérifier : x, y, z : 
    VFLIP: True
    HFLIP: True
    ZFLIP: False
    CONTRAST: True
    CONTRAST_FACTOR: (-0.3, 0.3)
    BRIGHTNESS: True
    BRIGHTNESS_FACTOR: (-0.3, 0.3)
    GAMMA_CONTRAST: True
    # GC_GAMMA: (0.5, 1.5)
    # ELASTIC: True
    CHANNEL_SHUFFLE: True
    AFFINE_MODE: 'reflect'

MODEL:
  ARCHITECTURE: unet
  FEATURE_MAPS : [8, 16, 32]
  #FEATURE_MAPS: [16, 32, 64]
  Z_DOWN: [0, 0] #regarder comment le z_down fonctionne en détail pour l'instant on pense qu'il faut pas apppliquer de z_down car données anisotrope : MODEL.Z_DOWN option can also be used to avoid downsampling in the z-axis, which is typically beneficial for anisotropic data
  DROPOUT_VALUES: [0.2, 0.3, 0.4]

  LOAD_CHECKPOINT: False


# MODEL:
#     ARCHITECTURE: attention_unet
#     FEATURE_MAPS: [48, 64, 80, 96]
#     Z_DOWN: [1,1,1]
#     LOAD_CHECKPOINT: False

TRAIN:
    ENABLE: True
    METRICS : ["iou", "cldice"]
    OPTIMIZER: ADAMW
    LR: 1.E-4 #à jouer d'autant plus
    BATCH_SIZE: 3
    EPOCHS: 500
    PATIENCE: 100 #à modifier 
    W_DECAY: 1e-4
    LR_SCHEDULER:
        NAME: 'reduceonplateau'
        REDUCEONPLATEAU_FACTOR: 0.5
        REDUCEONPLATEAU_PATIENCE: 10
        MIN_LR: 1e-6
    # LR_SCHEDULER:
    #     NAME: 'warmupcosine'
    #     MIN_LR: 1.E-6
    #     WARMUP_COSINE_DECAY_EPOCHS: 30

# TEST:
#     ENABLE: True
#     FULL_IMG: False
  
TEST:
    ENABLE: True
    METRICS : ["iou", "cldice"]
    AUGMENTATION: False
    FULL_IMG: False

LOSS:
    TYPE: CLDICE
    ITER : 10
    SMOOTH : 0.0000001
    ALPHA: 1.0

# SYSTEM:
#     NUM_CPUS: -1

# PROBLEM:
#     TYPE: IMAGE_TO_IMAGE
#     NDIM: 3D

# DATA: 
#     PATCH_SIZE: (32, 128, 128, 3)
#     TRAIN:                                                                                                              
#         PATH: /home/yasminebenjelloun/dataset/dataset_regression_3C_I2I_100/train/raw
#         GT_PATH: /home/yasminebenjelloun/dataset/dataset_regression_3C_I2I_100/train/label
#         IN_MEMORY: True
#     VAL:
#         SPLIT_TRAIN: 0.1
#     TEST:                                                                                                               
#         PATH: /home/yasminebenjelloun/dataset/dataset_regression_3C_I2I_100/test/raw
#         GT_PATH: /home/yasminebenjelloun/dataset/dataset_regression_3C_I2I_100/test/label
#         IN_MEMORY: True
#         LOAD_GT: True
#         PADDING: (4,16,16)

# AUGMENTOR:
#     ENABLE: False
#     RANDOM_ROT: True
#     VFLIP: True
#     HFLIP: True
#     ZFLIP: True
#     CHANNEL_SHUFFLE: True

# MODEL:
#     ARCHITECTURE: resunet++
#     FEATURE_MAPS: [16, 32, 64, 128, 256]
#     LOAD_CHECKPOINT: False
   
# TRAIN:
#     ENABLE: True
#     OPTIMIZER: ADAMW
#     LR: 1.E-3
#     BATCH_SIZE: 2
#     EPOCHS: 30
#     PATIENCE: 30

# TEST:
#     ENABLE: True
#     AUGMENTATION: False
#     FULL_IMG: False
# # LOSS:
# #     TYPE: MAE
